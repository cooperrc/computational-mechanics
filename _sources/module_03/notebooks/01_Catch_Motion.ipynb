{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6647ed7",
   "metadata": {},
   "source": [
    "> __Content modified under Creative Commons Attribution license CC-BY\n",
    "> 4.0, code under BSD 3-Clause License © 2020 R.C. Cooper__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33cd8f",
   "metadata": {},
   "source": [
    "# Catch things in motion\n",
    "\n",
    "This module of the _Computational Mechanics_ course is our launching pad to investigate _change_, _motion_, and _dynamics_, using computational thinking, Python, and Jupyter.\n",
    "\n",
    "The foundation of physics and engineering is the subject of **mechanics**: how things move around, when pushed around. Or pulled... in the beginning of the history of mechanics, Galileo and Newton sought to understand how and why objects fall under the pull of gravity.\n",
    "\n",
    "This first lesson will explore motion by analyzing images and video, to learn about velocity and acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0a65a",
   "metadata": {},
   "source": [
    "## Acceleration of a falling ball\n",
    "\n",
    "Let's start at the beginning. Suppose you want to use video capture of a falling ball to _compute_ the acceleration of gravity. Could you do it? With Python, of course you can!\n",
    "\n",
    "Here is a neat video you found online, produced over at MIT several years ago [1]. It shows a ball being dropped in front of a metered panel, while lit by a stroboscopic light. Watch the video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "vid = YouTubeVideo(\"xQ4znShlK5A\")\n",
    "display(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7c4b1",
   "metadata": {},
   "source": [
    "You learn from the video that the marks on the panel are every $0.25\\rm{m}$, and on the [website](http://techtv.mit.edu/collections/physicsdemos/videos/831-strobe-of-a-falling-ball) they say that the strobe light flashes at about 15 Hz (that's 15 times per second). The final [image on Flickr](https://www.flickr.com/photos/physicsdemos/3174207211), however, notes that the strobe fired 16.8 times per second. So you have some uncertainty already!\n",
    "\n",
    "Luckily, the MIT team obtained one frame with the ball visible at several positions as it falls. This, thanks to the strobe light and a long-enough exposure of that frame. What you'd like to do is use that frame to capture the ball positions digitally, and then obtain the velocity and acceleration from the distance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d8e25",
   "metadata": {},
   "source": [
    "You can find several toolkits for handling images and video with Python; you'll start with a simple one called [`imageio`](https://imageio.github.io). Import this library like any other, and let's load `numpy` and `pyplot` while you're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d34869",
   "metadata": {},
   "source": [
    "### Read the video\n",
    "\n",
    "With the `get_reader()` method of `imageio`, you can read a video from its source into a _Reader_ object. You don't need to worry too much about the technicalities here—you'll walk you through it all—but check the type, the length (for a video, that's number of frames), and notice you can get info, like the frames-per-second, using `get_meta_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897390be",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('https://go.gwu.edu/engcomp3vidmit', format='mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89807d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = reader.get_meta_data()['fps']\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645e50c",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "\n",
    "You may get this error after calling `get_reader()` if you're not running in the class Jupyter server:\n",
    "  \n",
    "```\n",
    "NeedDownloadError: Need ffmpeg exe. You can obtain it with either:\n",
    "  - install using conda: conda install ffmpeg -c conda-forge\n",
    "  - download using the command: imageio_download_bin ffmpeg\n",
    "  - download by calling (in Python): imageio.plugins.ffmpeg.download()\n",
    "```\n",
    "\n",
    "If you do, you suggest to install `imageio-ffmpeg` package, an ffmpeg wrapper for Python that includes the `ffmpeg` executable. You can install it via `conda`:\n",
    "\n",
    " `conda install imageio-ffmpeg -c conda-forge`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5af91",
   "metadata": {},
   "source": [
    "### Show a video frame in an interactive figure\n",
    "\n",
    "With `imageio`, you can grab one frame of the video, and then use `pyplot` to show it as an image. But you want to interact with the image, somehow.\n",
    "\n",
    "So far in this course, you have used the command `%matplotlib inline` to get our plots rendered _inline_ in a Jupyter notebook. There is an alternative command that gives you some interactivity on the figures: `%matplotlib notebook`. Execute this now, and you'll see what it does below, when you show the image in a new figure.\n",
    "\n",
    "Let's also set some font parameters for our plots in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a305fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c892c",
   "metadata": {},
   "source": [
    "Now you can use the `get_data()` method on the `imageio` _Reader_ object, to grab one of the video frames, passing the frame number. Below, you use it to grab frame number 1100, and then print the `shape` attribute to see that it's an \"array-like\" object with three dimensions: they are the pixel numbers in the horizontal and vertical directions, and the number of colors (3 colors in RGB format). Check the type to see that it's an `imageio` _Image_ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = reader.get_data(1100)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2312b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdf291",
   "metadata": {},
   "source": [
    "Naturally, `imageio` plays youll with `pyplot`. You can use\n",
    "[`plt.imshow()`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.plt.imshow.html)\n",
    "to show the image in a figure. Show frame 1100, it gives a good view of\n",
    "the long-exposure image of the falling ball.\n",
    "\n",
    "##### Explore:\n",
    "\n",
    "Check out the neat interactive options that you get with `%matplotlib notebook`. Then go back and change the frame number above, and show it below. Notice that you can see the $(x,y)$ coordinates of your cursor tip while you hover on the image with the mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411763ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c54ab5c",
   "metadata": {},
   "source": [
    "### Capture mouse clicks on the frame\n",
    "\n",
    "Okay! Here is where things get really interesting. Matplotlib has the ability to create [event connections](https://matplotlib.org/devdocs/users/event_handling.html?highlight=mpl_connect), that is, connect the figure canvas to user-interface events on it, like mouse clicks. \n",
    "\n",
    "To use this ability, you write a function with the events you want to capture, and then connect this function to the Matplotlib \"event manager\" using [`mpl_connect()`](https://matplotlib.org/devdocs/api/backend_bases_api.html#matplotlib.backend_bases.FigureCanvasBase.mpl_connect). In this case, you connect the `'button_press_event'` to the function named `onclick()`, which captures the $(x,y)$ coordinates of the mouse click on the figure. Magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2db8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    '''Capture the x,y coordinates of a mouse click on the image'''\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    coords.append([ix, iy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "\n",
    "coords = []\n",
    "connectId = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6205ad",
   "metadata": {},
   "source": [
    "Notice that in the previous code cell, you created an empty list named `coords`, and inside the `onclick()` function, you are appending to it the $(x,y)$ coordinates of each mouse click on the figure. After executing the cell above, you have a connection to the figure, via the user interface: \n",
    "\n",
    "## Exercise \n",
    "Click with your mouse on the endpoints of the white lines of the metered panel (click on the edge of the panel to get approximately equal $x$ coordinates), then print the contents of the `coords` list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997862c",
   "metadata": {},
   "source": [
    "The $x$ coordinates are pretty close, but there is some variation due to\n",
    "our shaky hand (or bad eyesight), and perhaps because the metered panel\n",
    "is not perfectly vertical. You can cast the `coords` list to a NumPy\n",
    "array, then grab all the first elements of the coordinate pairs, then\n",
    "get the standard deviation as an indication of our error in the\n",
    "mouse-click captures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(coords)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(coords)[:,0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cc4c3",
   "metadata": {},
   "source": [
    "Depending how shaky _your_ hand was, you may get a different value, but you got a standard deviation of about one pixel. Pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d1560",
   "metadata": {},
   "source": [
    "Now, let's grab all the second elements of the coordinate pairs, corresponding to the $y$ coordinates, i.e., the vertical positions of the white lines on the video frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20860754",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lines = np.array(coords)[:,1]\n",
    "y_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f9ff0",
   "metadata": {},
   "source": [
    "Looking ahead, what you'll do is repeat the process of capturing mouse clicks on the image, but clicking on the ball positions. Then, you will want to have the vertical positions converted to physical length (in meters), from the pixel numbers on the image.\n",
    "\n",
    "You can get the scaling from pixels to meters via the distance between two white lines on the metered panel, which you know is $0.25\\rm{m}$. \n",
    "\n",
    "Let's get the average vertical distance between two while lines, which you can calculate as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{\\Delta y} = \\sum_{i=0}^N \\frac{y_{i+1}-y_i}{N-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9032ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_lines = y_lines[1:] - y_lines[0:-1]\n",
    "gap_lines.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311c2a5",
   "metadata": {},
   "source": [
    "## Discussion \n",
    "\n",
    "* Why did you slice the `y_lines` array like that? If you can't explain it, write out the first few terms of the sum above and think!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d083d89",
   "metadata": {},
   "source": [
    "### Compute the acceleration of gravity\n",
    "\n",
    "You're making good progress! You'll repeat the process of showing the image on an interactive figure, and capturing the mouse clicks on the figure canvas: but this time, you'll click on the ball positions. \n",
    "\n",
    "Using the vertical displacements of the ball, $\\Delta y_i$, and the known time between two flashes of the strobe light, $1/16.8\\rm{s}$, you can get the velocity and acceleration of the ball! But first, to convert the vertical displacements to meters, you'll multiply by $0.25\\rm{m}$ and divide by `gap_lines.mean()`.\n",
    "\n",
    "Before clicking on the ball positions, you may want to inspect the\n",
    "high-resolution final [photograph on\n",
    "Flickr](https://www.flickr.com/photos/physicsdemos/3174207211)—notice\n",
    "that the first faint image of the falling ball is just \"touching\" the\n",
    "ring finger of Bill's hand. We decided _not_ to use that photograph in\n",
    "our lesson because the Flickr post says _\"All rights reserved\"_, while\n",
    "the video says specifically that it is licensed under a Creative Commons\n",
    "license. In other words, MIT has granted permission to use the video,\n",
    "but _not_ the photograph. _Sigh_.\n",
    "\n",
    "OK. Go for it: capture the clicks on the ball!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09495518",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "\n",
    "coords = []\n",
    "connectId = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e2922",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Click on the locations of the _ghost_ ball locations in the image above to populate `coords` with x-y-coordinates for the ball's location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords # view the captured ball positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b8565",
   "metadata": {},
   "source": [
    "Scale the vertical displacements of the falling ball as explained above (to get distance in meters), then use the known time between flashes of the strobe light, $1/16.8\\rm{s}$, to compute estimates of the velocity and acceleration of the ball at every captured instant, using:\n",
    "\n",
    "\\begin{equation}\n",
    "v_i = \\frac{y_{i+1}-y_i}{\\Delta t}, \\qquad a_i = \\frac{v_{i+1}-v_i}{\\Delta t}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coords = np.array(coords)[:,1]\n",
    "delta_y = (y_coords[1:] - y_coords[:-1]) *0.25 / gap_lines.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = delta_y * 16.8\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (v[1:] - v[:-1]) *16.8\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68914d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75040823",
   "metadata": {},
   "source": [
    "Yikes! That's some wide variation on the acceleration estimates. Our average measurement for the acceleration of gravity is not great, but it's not far off. The actual value you are hoping to find is $9.81\\rm{m/s}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e144cac",
   "metadata": {},
   "source": [
    "## Projectile motion\n",
    "\n",
    "Now, you'll study projectile motion, using a video of a ball \"fired\" horizontally, like a projectile. Here's a neat video you found online, produced by the folks over at [Flipping Physics](http://www.flippingphysics.com) [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "vid = YouTubeVideo(\"Y4jgJK35Gf0\")\n",
    "display(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a6bdd",
   "metadata": {},
   "source": [
    "We used Twitter to communicate with the author of the video and ask permission to use it in this lesson. A big _Thank You_ to Jon Thomas-Palmer for letting us use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">You have my permission to use the video. Please provide attribution to me. I’d enjoy seeing what you do with it too!</p>&mdash; Jon Thomas-Palmer (@FlippingPhysics) <a href=\"https://twitter.com/FlippingPhysics/status/926785273538666497?ref_src=twsrc%5Etfw\">November 4, 2017</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbbfad",
   "metadata": {},
   "source": [
    "### Capture mouse clicks on many frames with a widget\n",
    "\n",
    "Capture the coordinates of mouse clicks on a _sequence_ of images, so\n",
    "that you may have the positions of the moving ball caught on video. We\n",
    "know how to capture the coordinates of mouse clicks, so the next\n",
    "challenge is to get consecutive frames of the video displayed for us, to\n",
    "click on the ball position each time. \n",
    "\n",
    "Widgets to the rescue! There are currently [10 different widget types](http://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html) included in the `ipywidgets` library. The `BoundedIntText()` widget shows a text box with an integer value that can be stepped from a minimum to a maximum value by clicking up/down arrows. Stepping through frames with this widget, and clicking on the ball position each time, gets us what you want.\n",
    "\n",
    "Digitizing the ball positions in this way is a bit tedious. But this could be a realistic scenario: you captured video of a moving object, and you need to get position data from the video frames. Unless you have some fancy motion-capture equipment, this will do the trick.\n",
    "\n",
    "Let's load the Jupyter widgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc180f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877f950",
   "metadata": {},
   "source": [
    "Download the video, previously converted to .mp4 format to be read by `imageio`, and then load it to an `imageio` _Reader_. Notice that it has 3531 frames, and they are 720x1280 pixels in size. \n",
    "\n",
    "Below, you're showing frame number 52, which you found to be the start of the portion shown at 50% speed. Go ahead and use that frame to capture mouse clicks on the intersection of several $10\\rm{cm}$ lines with one vertical, so you can calculate the scaling from pixels to physical distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4492a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "URL = 'http://go.gwu.edu/engcomp3vid1?accessType=DOWNLOAD'\n",
    "urlretrieve(URL, 'Projectile_Motion.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('Projectile_Motion.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6026b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = reader.get_data(52)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "\n",
    "coords = []\n",
    "connectId = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b90eb",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Grab the coordinates of the 0, 10, 20, 30, 40, ..., 100-cm vertical positions so you can create a vertical conversion from pixels to centimeters with `gap_lines2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85320dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lines2 = np.array(coords)[:,1]\n",
    "y_lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_lines2 = y_lines2[1:] - y_lines2[0:-1]\n",
    "gap_lines2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15658f",
   "metadata": {},
   "source": [
    "Above, you repeated the process to compute the vertical distance between\n",
    "the $10\\rm{cm}$ marks (averaging over your clicks): the scaling of\n",
    "distances from this video will need multiplying by $0.1$ to get meters,\n",
    "and dividing by `gap_lines2.mean()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b05c8",
   "metadata": {},
   "source": [
    "Now the fun part! Study the code below: you create a `selector` widget of the `BoundedIntText` type, taking the values from 52 to 77, and stepping by 1. We already played around a lot with the video and found this frame range to contain the portion shown at 50% speed. \n",
    "\n",
    "Re-use the `onclick()` function, appending to a list named `coords`, and you call it with an event connection from Matplotlib, just like before. But now you add a call to [`widgets.interact()`](http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html), using a new function named `catchclick()` that reads a new video frame and refreshes the figure with it.\n",
    "\n",
    "Execute this cell, then click on the ball position, advance a frame, click on the new ball position, and so on, until frame 77. The mouse click positions will be saved in `coords`.\n",
    "\n",
    "Its better to click on the bottom edge of the ball image, rather than attempt to aim at the ball's center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9026eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = widgets.BoundedIntText(value=52, min=52, max=77, step=1,\n",
    "    description='Frame:',\n",
    "    disabled=False)\n",
    "\n",
    "coords = []\n",
    "\n",
    "def catchclick(frame):\n",
    "    image = reader.get_data(frame)\n",
    "    plt.imshow(image, interpolation='nearest');\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "connectId = fig.canvas.mpl_connect('button_press_event',onclick)\n",
    "\n",
    "widgets.interact(catchclick, frame=selector);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords # view the pixel coordinates of the projectile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b916904",
   "metadata": {},
   "source": [
    "Now, convert the positions in pixels to meters, using your scaling for\n",
    "this video, and save the $x$ and $y$ coordinates to new arrays. Below,\n",
    "you plot the ball positions that you captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(coords)[:,0] *0.1 / gap_lines2.mean()\n",
    "y = np.array(coords)[:,1] *0.1 / gap_lines2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cf3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatter plot of the projectile positions\n",
    "fig = plt.figure()\n",
    "plt.scatter(x,-y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078fbbff",
   "metadata": {},
   "source": [
    "Finally, compute the vertical displacements, then get the vertical velocity and acceleration. And why not repeat the process for the horizontal direction of motion. The time interval is $1/60$ seconds, according to the original video description, i.e., 60 frames per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_y = (y[1:] - y[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a263f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vy = delta_y * 60\n",
    "ay = (vy[1:] - vy[:-1]) * 60\n",
    "print('The acceleration in the y direction is: {:.2f}'.format(ay.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabfacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_x = (x[1:] - x[:-1])\n",
    "vx = delta_x * 60\n",
    "ax = (vx[1:] - vx[:-1]) * 60\n",
    "print('The acceleration in the x direction is: {:.2f}'.format(ax.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790f3fc",
   "metadata": {},
   "source": [
    "## Saving your hard work\n",
    "\n",
    "You have put a lot of effort into processing these images so far. Let's\n",
    "save your variables `time`, `x`, and `y` so you can load it back later. \n",
    "\n",
    "Use the command `np.savez(file_name, array1,array2,...)` to save your arrays for use later.\n",
    "\n",
    "The x-y-coordinates occur at 1/60 s, 2/60s, ... len(y)/60s = `np.arange(0,len(y))/60`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0,len(y))/60\n",
    "np.savez('../data/projectile_coords.npz',t=t,x=x,y=-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e61d66",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "* What did you get for the $x$ and $y$ accelerations? What did your colleagues get?\n",
    "* Do the results make sense to you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e27df9",
   "metadata": {},
   "source": [
    "## Numerical derivatives\n",
    "\n",
    "You just computed the average velocity between two captured ball positions using _numerical derivative_. The velocity is the _derivative_ of position with respect to time, and you can approximate its instantaneous value with the average velocity between two close instants in time:\n",
    "\n",
    "\\begin{equation}\n",
    "v(t) = \\frac{dy}{dt} \\approx \\frac{y(t_i+\\Delta t)-y(t_i)}{\\Delta t}\n",
    "\\end{equation}\n",
    "\n",
    "And acceleration is the _derivative_ of velocity with respect to time; you can approximate it with the average acceleration within a time interval:\n",
    "\n",
    "\\begin{equation}\n",
    "a(t) = \\frac{dv}{dt} \\approx \\frac{v(t_i+\\Delta t)-v(t_i)}{\\Delta t}\n",
    "\\end{equation}\n",
    "\n",
    "As you can imagine, the quality of the approximation depends on the size of the time interval: as $\\Delta t$ gets smaller, the error also gets smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8866f2",
   "metadata": {},
   "source": [
    "### Using high-resolution data\n",
    "\n",
    "Suppose you had some high-resolution experimental data of a falling ball. Might you be able to compute the acceleration of gravity, and get a value closer to the actual acceleration of $9.8\\rm{m/s}^2$?\n",
    "\n",
    "You're in luck! Physics professor Anders Malthe-Sørenssen of Norway has some high-resolution data on the youbsite to accompany his book [3]. We contacted him by email to ask for permission to use the data set of a falling tennis ball, and he graciously agreed. _Thank you!_ His data was recorded with a motion detector on the ball, measuring the $y$ coordinate at tiny time intervals of $\\Delta t = 0.001\\rm{s}$. Pretty fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64351fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/fallingtennisball02.txt'\n",
    "t, y = np.loadtxt(filename, usecols=[0,1], unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d025374",
   "metadata": {},
   "source": [
    "Okay! You should have two new arrays with the time and position data. Let's get a plot of the ball's vertical position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(t,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f7eac",
   "metadata": {},
   "source": [
    "Neat. The ball bounced 3 times during motion capture. Let's compute the\n",
    "acceleration during the first fall, before the bounce. A quick check on\n",
    "the `y` array shows that there are several points that take a negative\n",
    "value. Use the first negative entry as the top limit of a slice, and\n",
    "then compute displacements, velocity, and acceleration with that slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where( y < 0 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd69529",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_y = (y[1:576] - y[:575])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac810eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = t[1]-t[0]\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vy = delta_y / dt\n",
    "ay = (vy[1:] - vy[:-1]) / dt\n",
    "print('The acceleration in the y direction is: {:.2f}'.format(ay.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de2979",
   "metadata": {},
   "source": [
    "Gah. Even with this high-resolution data, you're getting an average value of acceleration that is smaller than the actual acceleration of gravity: $9.8\\rm{m/s}^2$. _What is going on?_ Hmm. Let's make a plot of the acceleration values…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(ay);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44112447",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "* What do you see in the plot of acceleration computed from the high-resolution data?\n",
    "* Can you explain it? What do you think is causing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42423132",
   "metadata": {},
   "source": [
    "## What you've learned\n",
    "\n",
    "* Work with images and videos in Python using `imageio`.\n",
    "* Get interactive figures using the `%matplotlib notebook` command.\n",
    "* Capture mouse clicks with Matplotlib's `mpl_connect()`.\n",
    "* Observed acceleration of falling bodies is less than $9.8\\rm{m/s}^2$.\n",
    "* Capture mouse clicks on several video frames using widgets!\n",
    "* Projectile motion is like falling under gravity, plus a horizontal velocity.\n",
    "* Save our hard work as a numpy .npz file __Check the Problems for loading it back into your session__\n",
    "* Compute numerical derivatives using differences via array slicing.\n",
    "* Real data shows free-fall acceleration decreases in magnitude from $9.8\\rm{m/s}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b52af1",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1.  Strobe of a Falling Ball (2008), MIT Department of Physics Technical Services Group, video under CC-BY-NC, available online on [MIT TechTV](http://techtv.mit.edu/collections/physicsdemos/videos/831-strobe-of-a-falling-ball).\n",
    "\n",
    "2. The Classic Bullet Projectile Motion Experiment with X & Y Axis Scales (2004), video by [Flipping Physics](http://www.flippingphysics.com/bullet-with-scales.html), Jon Thomas-Palmer. Used with permission.\n",
    "\n",
    "3. _Elementary Mechanics Using Python_ (2015), Anders Malthe-Sorenssen, Undergraduate Lecture Notes in Physics, Springer. Data at http://folk.uio.no/malthe/mechbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91d1d2",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "1. Instead of using $\\frac{\\Delta v}{\\Delta t}$, you can use the [numpy polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) to determine the acceleration of the ball. \n",
    "\n",
    "    a. Use your coordinates from the saved .npz file you used above to load your projectile motion data\n",
    "    \n",
    "    ```python\n",
    "    npz_coords = np.load('projectile_coords.npz')\n",
    "    t = npz_coords['t']\n",
    "    x = npz_coords['x']\n",
    "    y = npz_coords['y']```\n",
    "    \n",
    "    b. Calculate $v_x$ and $v_y$ using a finite difference again, then do a first-order polyfit to $v_x-$ and $v_y-$ vs $t$. What is the acceleration now?\n",
    "    \n",
    "    c. Now, use a second-order polynomial fit for x- and y- vs t. What is acceleration now?\n",
    "    \n",
    "    d. Plot the polyfit lines for velocity and position (2 figures) with the finite difference velocity data points and positions. Which lines look like better e.g. which line fits the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465ed45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea02b09",
   "metadata": {},
   "source": [
    "2. Not only can you measure acceleration of objects that you track, you can look at other physical constants like [coefficient of restitution](https://en.wikipedia.org/wiki/Coefficient_of_restitution), $e$ . \n",
    "\n",
    "     During a collision with the ground, the coefficient of restitution is\n",
    "     \n",
    "     $e = -\\frac{v_{y}'}{v_{y}}$ . \n",
    "     \n",
    "     Where $v_y'$ is y-velocity perpendicular to the ground after impact and $v_y$ is the y-velocity after impact. \n",
    "     \n",
    "     a. Calculate $v_y$ and plot as a function of time from the data `'../data/fallingtennisball02.txt'`\n",
    "     \n",
    "     b. Find the locations when $v_y$ changes rapidly i.e. the impact locations. Get the maximum and minimum velocities closest to the impact location. _Hint: this can be a little tricky. Try slicing the data to include one collision at a time before using  the `np.min` and `np.max` commands._\n",
    "     \n",
    "     c. Calculate the $e$ for each of the three collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32412cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
